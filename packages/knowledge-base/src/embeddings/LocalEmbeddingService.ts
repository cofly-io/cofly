import { pipeline, env, FeatureExtractionPipeline } from '@xenova/transformers';
import path from 'path';
import { ErrorType, AppError } from '@repo/common';
import { EmbeddingService } from "../types";
import { KnowledgeBaseInstance } from "../KnowledgeBaseManager";
import { DefaultConfig } from "../Constants";

// å…è®¸æœ¬åœ°æ¨¡å‹
env.allowLocalModels = true;

// ç¦æ­¢è”ç½‘ï¼ˆå¦åˆ™ä¼š fallback åˆ° Hugging Faceï¼‰
env.allowRemoteModels = false;

// ä¹Ÿå¯ä»¥æŒ‡å®šç¼“å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
env.cacheDir = path.resolve(process.env.MODEL_DIR_BASE || DefaultConfig.MODEL_DIR_BASE);

/**
 * æœ¬åœ°å‘é‡åŒ–æœåŠ¡å®ç°
 * ä½¿ç”¨ @xenova/transformers åº“å®ç°æœ¬åœ°å‘é‡åŒ–
 */
export class LocalEmbeddingService implements EmbeddingService {
    private pipeline: FeatureExtractionPipeline | null = null;
    private isInitialized = false;
    private initializationPromise: Promise<void> | null = null;

    constructor(private kb: KnowledgeBaseInstance) {
    }

    /**
     * åˆå§‹åŒ–å‘é‡åŒ–æ¨¡å‹
     */
    private async initialize(): Promise<void> {
        if (this.isInitialized) {
            return;
        }

        if (this.initializationPromise) {
            return this.initializationPromise;
        }

        this.initializationPromise = this._doInitialize();
        return this.initializationPromise;
    }

    private async _doInitialize(): Promise<void> {
        try {
            console.log(`Initializing embedding model: ${this.kb.config.embedding.model}`);

            // åˆ›å»ºç‰¹å¾æå–ç®¡é“
            this.pipeline = await pipeline('feature-extraction', this.kb.config.embedding.model, {
                local_files_only: true // è¿›ä¸€æ­¥å¼ºåˆ¶æœ¬åœ°
            });

            // ç¡®ä¿ç»´åº¦é…ç½®æ­£ç¡®ï¼ˆall-MiniLM-L6-v2 æ˜¯ 384ç»´ï¼‰
            this.kb.config.embedding.dimension = 384;

            this.isInitialized = true;
            console.log('Embedding model initialized successfully with 384 dimensions');
        } catch (error) {
            this.isInitialized = false;
            this.initializationPromise = null;

            const appError: AppError = {
                type: ErrorType.VECTORIZATION_FAILED,
                message: `Failed to initialize embedding model: ${error instanceof Error ? error.message : 'Unknown error'}`,
                details: {model: this.kb.config.embedding.model, error},
                timestamp: new Date(),
            };

            console.error('Failed to initialize embedding model:', appError);
            throw appError;
        }
    }

    /**
     * ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡è¡¨ç¤º
     */
    async generateEmbedding(text: string): Promise<number[]> {
        if (!text || text.trim().length === 0) {
            const error: AppError = {
                type: ErrorType.VALIDATION_ERROR,
                message: 'Text cannot be empty',
                timestamp: new Date(),
            };
            throw error;
        }

        await this.initialize();

        if (!this.pipeline) {
            const error: AppError = {
                type: ErrorType.VECTORIZATION_FAILED,
                message: 'Embedding pipeline not initialized',
                timestamp: new Date(),
            };
            throw error;
        }

        let retries = 0;
        while (retries < this.kb.config.embedding.maxRetries) {
            try {
                // é¢„å¤„ç†æ–‡æœ¬
                const processedText = this.preprocessText(text);

                // ç”Ÿæˆå‘é‡
                const result = await Promise.race([
                    this.pipeline(processedText),
                    new Promise((_, reject) =>
                        setTimeout(() => reject(new Error('Timeout')), this.kb.config.embedding.timeout)
                    ),
                ]);

                // æå–å‘é‡æ•°æ®
                const embedding = this.extractEmbedding(result);

                // éªŒè¯å‘é‡ç»´åº¦
                if (embedding.length !== this.kb.config.embedding.dimension) {
                    throw new Error(`Expected dimension ${this.kb.config.embedding.dimension}, got ${embedding.length}`);
                }

                return embedding;
            } catch (error) {
                retries++;
                console.warn(`Embedding generation attempt ${retries} failed:`, error);

                if (retries >= this.kb.config.embedding.maxRetries) {
                    const appError: AppError = {
                        type: ErrorType.VECTORIZATION_FAILED,
                        message: `Failed to generate embedding after ${this.kb.config.embedding.maxRetries} attempts: ${error instanceof Error ? error.message : 'Unknown error'}`,
                        details: {text: text.substring(0, 100), retries, error},
                        timestamp: new Date(),
                    };
                    throw appError;
                }

                // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                await new Promise(resolve => setTimeout(resolve, 1000 * retries));
            }
        }

        const error: AppError = {
            type: ErrorType.VECTORIZATION_FAILED,
            message: 'Unexpected error in embedding generation',
            timestamp: new Date(),
        };
        throw error;
    }

    /**
     * æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡è¡¨ç¤º
     */
    async generateBatchEmbeddings(texts: string[]): Promise<number[][]> {
        if (!texts || texts.length === 0) {
            return [];
        }

        // è¿‡æ»¤ç©ºæ–‡æœ¬
        const validTexts = texts.filter(text => text && text.trim().length > 0);
        if (validTexts.length === 0) {
            return [];
        }

        await this.initialize();

        const results: number[][] = [];
        const batchSize = this.kb.config.embedding.batchSize;

        // åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜é—®é¢˜
        for (let i = 0; i < validTexts.length; i += batchSize) {
            const batch = validTexts.slice(i, i + batchSize);
            console.log(`Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(validTexts.length / batchSize)}`);

            try {
                const batchResults = await this.processBatch(batch);
                results.push(...batchResults);
            } catch (error) {
                console.error(`Failed to process batch starting at index ${i}:`, error);

                // å¦‚æœæ‰¹å¤„ç†å¤±è´¥ï¼Œå°è¯•é€ä¸ªå¤„ç†
                for (const text of batch) {
                    try {
                        const embedding = await this.generateEmbedding(text);
                        results.push(embedding);
                    } catch (singleError) {
                        console.error('Failed to process single text, skipping:', singleError);
                        // è·³è¿‡å¤±è´¥çš„æ–‡æœ¬ï¼Œä½†è®°å½•é”™è¯¯
                    }
                }
            }
        }

        return results;
    }

    /**
     * å¤„ç†å•ä¸ªæ‰¹æ¬¡
     */
    private async processBatch(texts: string[]): Promise<number[][]> {
        if (!this.pipeline) {
            throw new Error('Pipeline not initialized');
        }

        const processedTexts = texts.map(text => this.preprocessText(text));

        const result = await Promise.race([
            this.pipeline(processedTexts),
            new Promise((_, reject) =>
                setTimeout(() => reject(new Error('Batch timeout')), this.kb.config.embedding.timeout * 2)
            ),
        ]);

        return this.extractBatchEmbeddings(result, texts.length);
    }

    /**
     * é¢„å¤„ç†æ–‡æœ¬
     */
    private preprocessText(text: string): string {
        const processed = text
            .trim()
            .replace(/\s+/g, ' '); // è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦

        // å¢åŠ é•¿åº¦é™åˆ¶ï¼Œé¿å…è¿‡åº¦æˆªæ–­
        // all-MiniLM-L6-v2 æ”¯æŒæœ€å¤§256 tokensï¼Œä½†è¿™é‡Œæ˜¯å­—ç¬¦æ•°
        return processed.substring(0, 1024);
    }

    /**
     * ä»æ¨¡å‹è¾“å‡ºä¸­æå–å•ä¸ªå‘é‡ï¼ˆæ·»åŠ å½’ä¸€åŒ–ï¼‰
     */
    private extractEmbedding(result: any): number[] {
        if (!result || !result.data || !result.dims) {
            throw new Error('Invalid embedding result format');
        }

        const [batchSize, seqLength, hiddenSize] = result.dims;

        console.log(`Single result dims: [${batchSize}, ${seqLength}, ${hiddenSize}]`);

        if (batchSize !== 1) {
            throw new Error(`Expected batch size 1 for single embedding, got ${batchSize}`);
        }

        // Mean pooling
        const embedding = new Array(hiddenSize).fill(0);

        for (let tokenIdx = 0; tokenIdx < seqLength; tokenIdx++) {
            for (let dimIdx = 0; dimIdx < hiddenSize; dimIdx++) {
                const dataIndex = tokenIdx * hiddenSize + dimIdx;
                embedding[dimIdx] += result.data[dataIndex];
            }
        }

        // æ±‚å¹³å‡
        for (let dimIdx = 0; dimIdx < hiddenSize; dimIdx++) {
            embedding[dimIdx] /= seqLength;
        }

        // ğŸ”¥ å…³é”®ä¿®å¤ï¼šå½’ä¸€åŒ–å‘é‡ï¼ˆå¯¹COSINEè·ç¦»å¾ˆé‡è¦ï¼‰
        const normalizedEmbedding = this.normalizeVector(embedding);

        return normalizedEmbedding;
    }

    /**
     * ä»æ¨¡å‹è¾“å‡ºä¸­æå–æ‰¹é‡å‘é‡ï¼ˆæ·»åŠ å½’ä¸€åŒ–ï¼‰
     */
    private extractBatchEmbeddings(result: any, expectedCount: number): number[][] {
        if (!result || !result.data || !result.dims) {
            throw new Error('Invalid batch embedding result format');
        }

        const [batchSize, seqLength, hiddenSize] = result.dims;

        console.log(`Batch result dims: [${batchSize}, ${seqLength}, ${hiddenSize}]`);

        if (batchSize !== expectedCount) {
            throw new Error(`Expected batch size ${expectedCount}, got ${batchSize}`);
        }

        const embeddings: number[][] = [];

        // å¯¹æ¯ä¸ªæ–‡æœ¬è¿›è¡Œå¤„ç†
        for (let batchIdx = 0; batchIdx < batchSize; batchIdx++) {
            const embedding = new Array(hiddenSize).fill(0);

            // å¯¹è¯¥æ–‡æœ¬çš„æ‰€æœ‰tokenè¿›è¡Œmean pooling
            for (let tokenIdx = 0; tokenIdx < seqLength; tokenIdx++) {
                for (let dimIdx = 0; dimIdx < hiddenSize; dimIdx++) {
                    // 3Då¼ é‡çš„ç´¢å¼•ï¼šbatch * (seq * hidden) + token * hidden + dim
                    const dataIndex = batchIdx * (seqLength * hiddenSize) + tokenIdx * hiddenSize + dimIdx;
                    embedding[dimIdx] += result.data[dataIndex];
                }
            }

            // é™¤ä»¥tokenæ•°é‡å¾—åˆ°å¥å­å‘é‡
            for (let dimIdx = 0; dimIdx < hiddenSize; dimIdx++) {
                embedding[dimIdx] /= seqLength;
            }

            // ğŸ”¥ å…³é”®ä¿®å¤ï¼šå½’ä¸€åŒ–æ¯ä¸ªå‘é‡
            const normalizedEmbedding = this.normalizeVector(embedding);
            embeddings.push(normalizedEmbedding);
        }

        return embeddings;
    }

    /**
     * ğŸ”¥ æ–°å¢ï¼šå‘é‡å½’ä¸€åŒ–æ–¹æ³•
     */
    private normalizeVector(embedding: number[]): number[] {
        // è®¡ç®—å‘é‡çš„L2èŒƒæ•°
        const norm = Math.sqrt(embedding.reduce((sum: number, val: number) => sum + val * val, 0));

        if (norm === 0) {
            console.warn('Zero vector detected, cannot normalize');
            return embedding;
        }

        // å½’ä¸€åŒ–ï¼šæ¯ä¸ªåˆ†é‡é™¤ä»¥èŒƒæ•°
        const normalizedEmbedding = embedding.map((val: number) => val / norm);

        // è°ƒè¯•ä¿¡æ¯
        console.log('Vector norm before normalization:', norm.toFixed(6));
        console.log('Vector sample after normalization:', normalizedEmbedding.slice(0, 3).map((v: number) => v.toFixed(6)));

        return normalizedEmbedding;
    }

    /**
     * ğŸ”¥ æ–°å¢ï¼šæµ‹è¯•å‘é‡è´¨é‡çš„æ–¹æ³•
     */
    async testVectorQuality(): Promise<void> {
        console.log('=== Testing Vector Quality ===');

        try {
            // æµ‹è¯•ç›¸åŒæ–‡æœ¬
            const text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£";
            const vec1 = await this.generateEmbedding(text);
            const vec2 = await this.generateEmbedding(text);

            const selfSimilarity = this.cosineSimilarity(vec1, vec2);
            console.log('Self similarity (should be ~1.0):', selfSimilarity.toFixed(6));

            // æµ‹è¯•ç›¸ä¼¼æ–‡æœ¬
            const similarText = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶";
            const vec3 = await this.generateEmbedding(similarText);
            const similarSimilarity = this.cosineSimilarity(vec1, vec3);
            console.log('Similar text similarity:', similarSimilarity.toFixed(6));

            // æµ‹è¯•ä¸åŒæ–‡æœ¬
            const differentText = "å®Œå…¨ä¸ç›¸å…³çš„å†…å®¹å…³äºå¤©æ°”";
            const vec4 = await this.generateEmbedding(differentText);
            const differentSimilarity = this.cosineSimilarity(vec1, vec4);
            console.log('Different text similarity:', differentSimilarity.toFixed(6));

            // æ£€æŸ¥å‘é‡ç»Ÿè®¡ä¿¡æ¯
            const stats = this.analyzeVector(vec1);
            console.log('Vector stats:', stats);

        } catch (error) {
            console.error('Vector quality test failed:', error);
        }

        console.log('===============================');
    }

    /**
     * ğŸ”¥ æ–°å¢ï¼šè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
     */
    private cosineSimilarity(a: number[], b: number[]): number {
        if (a.length !== b.length) {
            throw new Error('Vectors must have the same length');
        }

        const dotProduct = a.reduce((sum: number, val: number, i: number) => sum + val * b[i]!, 0);
        const normA = Math.sqrt(a.reduce((sum: number, val: number) => sum + val * val, 0));
        const normB = Math.sqrt(b.reduce((sum: number, val: number) => sum + val * val, 0));

        if (normA === 0 || normB === 0) {
            return 0;
        }

        return dotProduct / (normA * normB);
    }

    /**
     * ğŸ”¥ æ–°å¢ï¼šåˆ†æå‘é‡ç»Ÿè®¡ä¿¡æ¯
     */
    private analyzeVector(embedding: number[]) {
        const min = Math.min(...embedding);
        const max = Math.max(...embedding);
        const mean = embedding.reduce((sum: number, val: number) => sum + val, 0) / embedding.length;
        const norm = Math.sqrt(embedding.reduce((sum: number, val: number) => sum + val * val, 0));

        return {
            min: min.toFixed(6),
            max: max.toFixed(6),
            mean: mean.toFixed(6),
            norm: norm.toFixed(6),
            length: embedding.length
        };
    }

    /**
     * æ£€æŸ¥æœåŠ¡æ˜¯å¦å°±ç»ª
     */
    isReady(): boolean {
        return this.isInitialized && this.pipeline !== null;
    }

    /**
     * è·å–æ¨¡å‹ä¿¡æ¯
     */
    getModelInfo(): { model: string; dimension: number } {
        return {
            model: this.kb.config.embedding.model,
            dimension: this.kb.config.embedding.dimension,
        };
    }

    /**
     * æ¸…ç†èµ„æº
     */
    async dispose(): Promise<void> {
        if (this.pipeline) {
            // @xenova/transformers çš„ç®¡é“é€šå¸¸ä¸éœ€è¦æ˜¾å¼æ¸…ç†
            this.pipeline = null;
        }
        this.isInitialized = false;
        this.initializationPromise = null;
    }
}